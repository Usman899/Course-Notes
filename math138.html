<!DOCTYPE html>
<html>
  <head>
    <title>MATH 138 Final Review by Raphael Koh</title>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
      });
    </script>
  </head>
  <body>
    <h1><b>1 </b>Review of Integration</h1>
    <h2>Riemann Integral</h2>
    Let $f(x)$ be a continuous (or piecewise continuous) function defined over $[a,b]$.
    <ol>
      <li>We partition $[a,b]$ into $n$ intervals such that each interval has has width $\Delta x=\frac{b-a}{n}$ with partition points $x_k=a+k\Delta x$, $0\leq k\leq n$.  Note that the endpoints are $x_0=a$ and $x_n=b$.</li>
      <li>
        For each interval $I_k=[x_{k-1}, x_k]$, $1\leq k\leq n$, pick a sample point $x_k^*\in I_k$.  This sample point can be the left endpoint ($x_{k-1}$), the right endpoint ($x_k$) or midpoint.
      </li>
      <li>
        Construct Riemann Sum: $$S_n=\sum_{k=1}^n f(x_k^*)\Delta x$$
      </li>
      <li>
        Take the limit: $$S=\lim_{n\to\infty}S_n=\lim_{n\to\infty}\sum_{k=1}^n f(x_k^*)\Delta x=\int_a^b f(x) dx$$
      </li>
    </ol>
    <br />
    <h2>Properties of Integrals</h2>
    <ol>
      <li>$\int_a^b c dx=c(b-a)$</li>
      <li>$\int_a^b [f(x)+g(x)] dx=\int_a^b f(x) dx+\int_a^b g(x) dx$</li>
      <li>$\int_a^b cf(x) dx=c\int_a^b f(x) dx$</li>
      <li>$\int_a^c f(x) dx+\int_c^b f(x) dx=\int_a^b f(x) dx$</li>
    </ol>
    <br />
    <br />
    <h2>Fundamental Theorem oF Calculus 1</h2>
    Let $f(x)$ be continuous on $[a,b]$.
    Given the function $$g(x)=\int_a^x f(t)dt,\quad a\leq x\leq b$$
    Then $g(x)$ is continuous on $[a,b]$ and $$g'(x)=f(x),\quad a\leq x\leq b$$
    <h2>Fundamental Theorem of Calculus 2</h2>
    Let $F(x)$ be any antiderivative of $f(x)$, then $$\int_a^b f(x)dx = F(b) - F(a)$$
    <br />
    <br />
    <br />
    <h2>Integration by Substitution</h2>
    e.g. $\int \sqrt{5x+4}dx$. <br /><br />
    Let $u=5x+4$, $du=5dx$,
    <br /><br />
    $\begin{align*}
      \int \sqrt{5x+4}dx&=\frac{1}{5}\int u^{\frac{1}{2}}du\\
      &=\frac{2}{3}\frac{1}{5}u^{\frac{3}{2}} + C\\
      &=\frac{2}{15}(5x+4)^{\frac{3}{2}} + C\\
    \end{align*}$
    <h2>Integration By Parts</h2>
    $$\int udv=uv-\int vdu$$
    <br />
    e.g. $\int xe^xdx$ <br /><br />
    Let $u=x$, $v=e^x$, $du=dx$, $dv=e^x$.
    $$\int xe^xdx=xe^x-\int e^xdx=xe^x-e^x+C$$
    <br />
    <br />
    <h2>Average of a Function</h2>
    Given a function continuous over $[a,b]$,
    <ol>
      <li>
        Partition $[a,b]$ into $n$ intervals of width $\Delta x=\frac{b-a}{n}$ and $x_n=a+k\Delta x$.
      </li>
      <li>
        Pick a sample point $x_k^*\in [x_{k-1},x_k]$.
      </li>
      <li>
        $$\begin{align*}
          \overline{f(x)}&\approx \frac{1}{n}\sum_{k=1}^nf(x_k^*)\\
          &=\frac{1}{n\Delta x}\sum_{k=1}^nf(x_k^*)\Delta x\\
          &=\frac{1}{n(\frac{b-a}{n})}\sum_{k=1}^nf(x_k^*)\Delta x\\
          &=\frac{1}{b-a}\sum_{k=1}^nf(x_k^*)\Delta x\\
        \end{align*}$$
      </li>
      <li>
        Taking the limit as $n\to\infty$,
        $$\begin{align*}
          \overline{f(x)}&=\frac{1}{b-a}\lim_{n\to\infty}\sum_{k=1}^nf(x_k^*)\Delta x\\
          &=\frac{1}{b-a}\int_a^b f(x)dx\\
        \end{align*}$$
      </li>
    </ol>
    <br /><br />
    <h2>Trigonometric Functions</h2>
    <h3>Strategy for Evaluating $\int \sin^mx\ \cos^nx\ dx$</h3>
    <ul>
      <li>
        If power of cosine is odd, $n=2k+1$, save one cosine and use $\cos^2x=1-\sin^2x$ to get
        $$\int \sin^mx\ \cos^{2k+1}x\ dx=\int \sin^mx(1-\sin^2x)^k\cos x\ dx$$
        Then, subsitute $u=\sin x$.
      </li>
      <li>
        If power of sine is odd, similar process as above.
      </li>
      <li>
        If both powers are even, use double angle identities:
        $$\sin^2x=\frac{1}{2}(1-cos2x)\quad\quad\cos^2x=\frac{1}{2}(1+cos2x)\quad\quad\sin x\cos x=\frac{1}{2}\sin 2x$$
      </li>
    </ul>
    <br />
    <h3>Strategy for Evaluating $\int \tan^mx\ \sec^nx\ dx$</h3>
    <ul>
      <li>
        If power of secant is even, $n=2k, k\geq 2$, save one $\sec^2x$ and use $\sec^2x=1+\tan^2x$ to get
        $$\int \tan^mx\ \sec^{2k}x\ dx=\int \tan^mx(1+\tan^2x)^{k-1}\sec^2 x\ dx$$
        Then, subsitute $u=\tan x$.
      </li>
      <li>
        If power of tangent is odd, $m=2k+1$, save one $\sec x\tan x$ and use $\tan^2x=\sec^2x-1$ to get
        $$\int \tan^{2k+1}x\ \sec^nx\ dx=\int (\sec^2x-1)^k\sec^{n-1}x\sec x\tan x\ dx$$
        Then, subsitute $u=\sec x$.
      </li>
    </ul>
    <br />
    <br />
    <h2>Trigonometric Substitution</h2>
    This technique is used when you find:
    $$\sqrt{A-x^2}\quad\quad\sqrt{A+x^2}\quad\quad\sqrt{x^2-A}$$
    We use the following trig id's:
    $$\sin^2x+\cos^2x=1\quad\quad\tan^2x+1=\sec^2x$$
    <h3>Integrals with $\sqrt{a^2-x^2}$</h3>
    e.g. $\int\sqrt{a^2-x^2}$<br /><br />
    Let $x=a\sin u$, $dx=a\cos u\ du$.<br /><br /> $\sqrt{a^2-x^2}=\sqrt{a^2-a^2\sin^2u}=a\sqrt{1-\sin^2u}=a\cos u$
    <br /><br />
    $\begin{align*}
      \int\sqrt{a^2-x^2}dx&=\int a^2\cos^2u\ du\\
      &=\frac{a^2}{2}\int (1+\cos 2u)du\\
      &=\frac{a^2}{2}(u+\frac{\sin2u}{2})+C\\
      &=\frac{a^2}{2}(u+\sin u\cos u)+C\\
      &=\frac{a^2}{2}\big(\sin^{-1}(\frac{x}{a})+\frac{x}{a}\frac{\sqrt{a^2-x^2}}{a}\big)+C\\
      &=\frac{a^2}{2}\sin^{-1}(\frac{x}{a})+\frac{x}{2}\sqrt{a^2-x^2}+C
    \end{align*}$
    <h3>Integrals with $\sqrt{a^2+x^2}$</h3>
    Substitute $x=a\tan u$.  Similar method as above.
    <h3>Integrals with $\sqrt{x^2-a^2}$</h3>
    Substitute $x=a\sec u$.  Similar method as above.
    <br /><br /><br /><br />
    <h2>Partial Fractions</h2>
    Used to integrate rational functions by expressing it as a sum of simple fractions.
    Given a rational function, $\frac{P(x)}{Q(x)}$, if $\deg (P) < \deg (Q)$ then it can be expressed as a partial fraction.  If not, perform polynomial division to get $\frac{P(x)}{Q(x)}=S(x)+\frac{R(x)}{Q(x)}$ such that $\deg (R) < \deg (Q)$.
    Split the fractions into the form $\frac{A}{ax+b}+\frac{B}{cx+d}$.<br />
    e.g. $$\begin{align*}
      \int\frac{4x+1}{x^2-x-2}dx&=\int\frac{4x+1}{(x+1)(x-2)}dx\\
      &=\int(\frac{3}{x-2}+\frac{1}{x+1}) dx\\
      &=3\ln|x-2|+\ln|x+1|+C
    \end{align*}$$
    <h3>Repeated Roots</h3>
    If a root is repeated $k$ times, we must repeat that term $k$ times such that
    $\frac{P(x)}{(ax+b)^k}=\frac{A_1}{ax+b}+\frac{A_2}{(ax+b)^2}+\cdots+\frac{A_k}{(ax+b)^k}$.
    <h3>Complex Roots</h3>
    If a function has $Q(x)$ with irreducible quadratic factors, the partial fraction will be of the form $\frac{Ax+B}{ax^2+bx+c}$.  Complete the square and use
    $$\int\frac{dx}{x^2-a^2}=\frac{1}{a}\tan^{-1}\big(\frac{x}{a}\big)+C$$
    <h3>Repeated Complex Roots</h3>
    $$\frac{P(x)}{Q(x)^k}=\frac{A_1x+B_1}{Q(x)}+\frac{A_2x+B_2}{Q(x)^2}+\cdots+\frac{A_kx+B_k}{Q(x)^k}$$
    <br /><br /><br /><br />
    <h2>Conservative Forces & Potential Energy</h2>
    $\vec{F}=f(x)\hat{i}$ is conservative if there exists a function $U(x)$ such that $f(x)=-U'(x)$, where $U(x)$ is the potential energy function.  So, $U(x)=-\int f(x)dx$.<br />
    <u>Consequence:</u>  If $\vec{F}$ acts on a mass $m$ to move it from $x=a$ to $x=b$, the work done is:
    $$\int_a^bf(x)dx=-\int_a^bU'(x)dx=-[U(b)-U(a)]=-\Delta U$$
    Alternatively, we can let $x=a$ be a reference point and define $U(x)=-\int_a^xf(s)ds$.  We define $U(a)=0$.  If $f(x)=-mg$, $U(x)=-\int_a^x-mg\ ds=mgx-mga=mgx$.<br /><br />
    <u>Physical Interpretation:</u>  $U(x)$ is the work done <u>against</u> the force when $m$ is moved from $a$ to $x$.  If $U(x)>0$, we have to work <u>against</u> the force to move $m$ from $a$ to $x$ (i.e. causes a "buildup" of PE). <br /><br />
    <u>Theorem: </u> Suppose that a mass $m$ is moving on the $x$-axis under the influence of a conservative force $\vec{F}(x)=f(x)\hat{i}$ according to Newton's Second Law of Motion, $\vec{F}=m\vec{a}$.  Then, the total mechanical energy of the mass is constant in time. <br />
    <u>Proof: </u>Total energy $E=KE+PE$.  Let $x(t)$ be the trajectory of the mass.  Then, $E(t)=\frac{1}{2}mv(t)^2+U(x(t))$ where $U'(x)=-f(x)$.
    $$\begin{align*}
      E'(t)=\frac{dE}{dt}&=\frac{1}{2}m\frac{d}{dt}v(t)^2+\frac{d}{dt}U(x(t))\\
      &=mv(t)v'(t)+U'(x(t))x'(t)\\
      &=mv(t)a(t)-f(x(t))v(t)\\
      &=v(t)[ma(t)-f(x(t))]\\
      &=v(t)[ma(t)-ma(t)]\\
      &=0\quad\square
    \end{align*}$$
    <br /><br /><br /><br />
    <h2>Applications of Integration</h2>
    <h3>Centre of Mass</h3>
    $$\bar{x}=\frac{\sum_{i=0}^nm_ix_i}{\sum_{i=0}^nm_i}$$
    Consider an object of length $L$ with a continuous mass distribution, $\rho(x)$, lying on the $x$-axis with one end on the origin.
    $$\Delta m\approx\rho(x_k^*)\Delta x$$
    $$M=\int_0^L\rho(x)dx$$
    $$\bar{x}\approx\frac{\sum_{i=1}^n\Delta m_ix_i^*}{\sum_{i=1}^n\Delta m_i}=\frac{\sum_{i=1}^n\rho(x_i^*)x_i^*\Delta x}{\sum_{i=1}^n\rho(x_i^*)\Delta x}$$
    $$\bar{x}=\lim_{n\to\infty}\bigg(\frac{\sum_{i=1}^n\rho(x_i^*)x_i^*\Delta x}{\sum_{i=1}^n\rho(x_i^*)\Delta x}\bigg)=\frac{\int_0^L\rho(x)x dx}{\int_0^L\rho(x)dx}=\frac{1}{M}\int_0^Lx\rho(x)dx$$
    <h3>Centre of Mass of Centroids</h3>
    Given $f(x)$ and $g(x)$ where $f(x)>g(x)$ and are continuous over $(a,b)$. Then
    $$dA=[f(x)-g(x)]dx$$
    First moment w.r.t $y$-axis: $dM_y=xdA$.  Net moment w.r.t $y$-axis: $M_y=\int_a^bxdA=\int_a^bx[f(x)-g(x)]dx$<br />
    The $x$-coordinate of the Centre of Mass is determimed by
    $$\int_a^b(x-\bar{x})dA=0$$
    $$\int_a^bx\ dA=\bar{x}\int_a^bdA$$
    $$\bar{x}=\frac{\int_a^bx\ dA}{\int_a^bdA}=\frac{M_y}{A}=\frac{\int_a^bx[f(x)-g(x)]dx}{\int_a^b[f(x)-g(x)]dx}$$
    Similarly, the $y$-coordinate of the Centre of Mass can be found by:
    $$\bar{y}=\frac{M_x}{A}=\frac{\int_a^by\ dA}{\int_a^bdA}$$
    Note that $\bar{x}$ can be determined from $y$ and $\bar{y}$ from $x$ by using the midpoint.
    $$M_x=\frac{1}{2}\int[f(x)+g(x)]dA$$
    <br /><br /><br /><br />
    <h3>Computation of Arclength</h3>
    Given a function $f(x)$ continuous over $[a,b]$, we want to find its arclength.
    <ol>
      <li>
        Partition into $n$ sub-intervals such that for each sub-interval $[x_{k-1},x_k]$ has an arclength of $C_k\approx||\overrightarrow{P_{k-1}P_k}||=\sqrt{\Delta x^2+\Delta y^2}=\sqrt{\Delta x^2+[f(x_k)-f(x_{k-1})]^2}=\Delta x\sqrt{1+\bigg[\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}\bigg]^2}$<br />
        By the Mean Value Theorem, there exists a $x_k^*\in[x_{k-1},x_k]$ such that $f'(x_k^*)=\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}$, so $C_k\approx\Delta x\sqrt{1+f'(x_k^*)^2}$
      </li>
      <li>
        Sum over all intervals.
        $$L\approx\sum_{k=1}^nC_k=\sum_{k=1}^n\sqrt{1+f'(x_k^*)^2}\Delta x$$
      </li>
      <li>
        Take $n\to\infty$.
        $$L=\lim_{n\to\infty}\sum_{k=1}^n\sqrt{1+f'(x_k^*)^2}\Delta x=\int\sqrt{1+f'(x)^2}dx$$
      </li>
    </ol> <br />
    Similarly, given a curve $C$, $$L=\int_Cds=\int_C\sqrt{dx^2+dy^2}=\int_Cdx\sqrt{1+\frac{dy}{dx}^2}=\int_a^b\sqrt{1+f'(x)^2}dx$$
    <br /><br />
    <h3>Computation of Centroids of Curves</h3>
    Consider a function $f(x)$ continuous over $[a,b]$.  Let $C$ represent the curve with linear density $\rho_0=1$, so $dm=\rho_0ds=ds$.<br />
    Moment w.r.t $y$-axis: $dM_y=xds\ \rightarrow\ M_y=\int_CdM_y=\int_Cxds$<br />
    Moment w.r.t $x$-axis: $dM_x=yds\ \rightarrow\ M_x=\int_CdM_x=\int_Cyds$<br /><br />
    Recall that for centroid($\bar{x},\bar{y}$):<br />
    $$\int_C(x-\bar{x})ds=0\quad\text{Net moment w.r.t $\bar{x}$}$$
    $$\int_C(y-\bar{y})ds=0\quad\text{Net moment w.r.t $\bar{y}$}$$
    So, $$\int_Cxds=\bar{x}\int_Cds\ \rightarrow\ \bar{x}=\frac{\int_Cxds}{\int_Cds}=\frac{\int_Cxds}{L}$$
    Similarly, $$\bar{y}=\frac{\int_Cyds}{L}$$
    <br /><br /><br /><br />
    <h2>Improper Integrals</h2>
    <h3>Type I - Integrals over infinite domains</h3>
    $$\int_{-\infty}^\infty f(x)dx=\int_{-\infty}^af(x)dx+\int_{a}^\infty f(x)dx=\lim_{b\to\infty}I_1(b)+\lim_{b\to\infty}I_2(b)=\lim_{b\to\infty}\int_{-b}^af(x)dx+\lim_{b\to\infty}\int_{a}^{\infty}f(x)dx$$
    <h3>Important Class of Improper Integrals</h3>
    Consider $I_P=\int_1^\infty \frac{1}{x^P}dx,\ P\in\mathbb{R}$.  $I_P$ converges for $P>1$ and diverges for $p\leq 1$.  This class of integrals is useful for "comparison tests" to determine whether the improper integral converges/diverges.
    <br /><br /><br /><br />
    <h3>Comparison Test</h3>
    Given functions $f(x), g(x)$ such that  $f(x)\geq g(x)\geq 0$ for all $x\geq a$, then $\int_a^bf(x)dx\geq\int_a^bg(x)dx$.
    <ol>
      <li>
        If $\int_a^\infty f(x)dx$ converges, then $\int_a^\infty g(x)dx$ converges.
      </li>
      <li>
        If $\int_a^\infty g(x)dx$ diverges, then $\int_a^\infty f(x)dx$ diverges.
      </li>
    </ol>
    <h3>Type II - Discontinuous and (possibly) unbounded at a point $c\in[a,b]$</h3>
    <ol>
      <li>
        $f(x)$ is continuous on $[a,b)$ and discontinuous at $b$, then $\int_a^b f(x)dx=\lim_{t\to b^-}\int_a^t f(x)dx$
      </li>
      <li>
        $f(x)$ is continuous on $(a,b]$ and discontinuous at $a$, then $\int_a^b f(x)dx=\lim_{t\to a^+}\int_t^b f(x)dx$
      </li>
      <li>
        $f(x)$ is continuous on $[a,b]$ except at $c\in(a,b)$, then $\int_a^b f(x)dx=\lim_{t\to c^-}\int_a^t f(x)dx+\lim_{t\to c^+}\int_t^b f(x)dx$
      </li>
    </ol>
    <br /><br /><br /><br />
    <h2>Differential Equations</h2>
    A differential equation involves derivaties of a function and possibly the function itself.<br />
    <u>Definition</u>: The <b>order of a DE</b> is the order of the highest derivative in the DE.<br />
    <u>Definition</u>: A DE is <b>linear</b> if the dependent variable or derivative is not multiplied by itself or each other (i.e. $y + \frac{dy}{dx}$).<br /><br />
    <h3>Separable First-Order DEs</h3>
    A DE is <u>separable</u> if it can be written in the form $\frac{dy}{dx}=g(x)f(y)$. <br />
    e.g. <ol>
      <li>
        $\frac{dy}{dx}=xy\quad\checkmark$
      </li>
      <li>
        $\frac{dy}{dx}=(x+1)(y^2+1)\quad\checkmark$
      </li>
      <li>
        $\frac{dy}{dx}=x+y\quad\times$
      </li>
    </ol>
    To solve a separable DE:
    <ol>
      <li>
        Divide by $f(y)$.
        $$\frac{1}{f(y)}\frac{dy}{dx}=g(x)\quad *f(y)\neq 0$$
        If $f(y^*)=0$, then $y(x)=y^*$ is a constant solution to the DE.
      </li>
      <li>
        Let $h(y)=\frac{1}{f(y)}$, so $h(y)\frac{dy}{dx}=g(x)$.
      </li>
      <li>
        Integrate both sides and solve.
        $$\int h(y)dy=\int g(x)dx$$
      </li>
    </ol>
    e.g. $\frac{dy}{dx}=xy$
    <ol>
      <li>
        Divide by $y$. $$\frac{1}{y}\frac{dy}{dx}=x\quad\textbf{*Check: } y=0\rightarrow\frac{dy}{dx}=x\cdot 0=0\ \rightarrow y(x)=0\text{ is a solution.}$$
      </li>
      <li>
        Integrate. $$\int\frac{1}{y}dy=\int xdx$$
      </li>
      <li>
        Solve.
        $$\begin{align*}
          \ln|y|&=\frac{1}{2}x^2+C\\
          |y|&=e^{\frac{1}{2}x^2+C}\\
          y&=\pm e^Ce^{\frac{1}{2}x^2}\\
          y&=Ae^{\frac{x^2}{2}}\quad A\neq 0\\
          \text{But, $y=0$ is a solution, }y&=Ce^{\frac{1}{2}x^2}\quad , C\in\mathbb{R}
        \end{align*}$$
      </li>
    </ol><br /><br />
    <h3>Linear First-Order DE</h3>
    $$\text{General Form: }\frac{dy}{dx}+P(x)y=Q(x)$$
    To solve,
    <ol>
      <li>
        Multiply both sides by the integrating factor, $I(x)=e^{\int P(x)dx}$
        $$e^{\int P(x)dx}\frac{dy}{dx}+e^{\int P(x)dx}P(x)y=Q(x)e^{\int P(x)dx}$$
        $$\frac{d}{dx}[ye^{\int P(x)dx}]=Q(x)e^{\int P(x)dx}$$
      </li>
      <li>
        Integrate both sides.
        $$ye^{\int P(x)dx}+C=\int Q(x)ye^{\int P(x)dx}dx$$
      </li>
      <li>
        Solve for y.
        $$y(x)=e^{-\int P(x)dx}\int Q(x)ye^{\int P(x)dx}dx-Ce^{-\int P(x)dx}$$
      </li>
    </ol>
    e.g. Solve $\frac{dy}{dx}+2y=x$.<br />
    $P(x)=2,\ Q(x)=x,\ I(x)=e^{\int 2dx}=e^{2x}$
    <ol>
      <li>
        Multiply by $I(x)$. $$e^{2x}\frac{dy}{dx}+2ye^{2x}=xe^{2x}$$
        $$\frac{d}{dx}[ye^{2x}]=xe^{2x}$$
      </li>
      <li>
        Integrate.
        $$ye^{2x}+C_1=\int xe^{2x}dx$$
        Let $u=x,\ du=dx,\ dv=e^{2x}dx,\ v=\frac{1}{2}e^{2x}$.
        $$ye^{2x}=\frac{1}{2}xe^{2x}-\int \frac{1}{2}e^{2x}dx +C_2$$
        $$ye^{2x}=\frac{1}{2}xe^{2x}-\frac{1}{4}e^{2x} +C$$
      </li>
      <li>
        Solve for y.
        $$y=\frac{1}{2}x-\frac{1}{4} +Ce^{-2x}\quad\square$$
      </li>
    </ol>
    e.g. <b>[Physics]</b> Projectile Motion with Air Resistance<br />
    $$m\frac{dv}{dt}=-mg-kv_y\ \rightarrow\ \frac{dv}{dt}=-g-\frac{k}{m}v_y$$
    Let's rewrite this in terms of a first-order linear DE.
    $$\frac{dv}{dt}+\frac{k}{m}v=-g\quad P(t)=\frac{k}{m},\ Q(t)=-g,\ I(t)=e^{\int \frac{k}{m}dt}=e^{\frac{kt}{m}}$$
    We multiply by $I(t)$: $$e^{\frac{kt}{m}}\frac{dv}{dt}+\frac{k}{m}ve^{\frac{kt}{m}}=-ge^{\frac{kt}{m}}$$
    $$\frac{d}{dt}[ve^{\frac{kt}{m}}]=-ge^{\frac{kt}{m}}$$
    Integrate both sides:
    $$ve^{\frac{kt}{m}}+C_1=-\int ge^{\frac{kt}{m}}$$
    $$ve^{\frac{kt}{m}}=-\frac{mg}{k}e^{\frac{kt}{m}}+C$$
    Solve for v. $$v=-\frac{mg}{k}+Ce^{-\frac{kt}{m}}$$
    If we impose <i>initial condition</i> such that $v_y(0)=v_0\sin\theta$,
    $v(0)=v_0\sin\theta=-\frac{mg}{k}+Ce^{-\frac{k(0))}{m}}=-\frac{mg}{k}+C$
    So, $C=v_0\sin\theta+\frac{mg}{k}$.
    $$\therefore v(t)=(v_0\sin\theta+\frac{mg}{k})e^{-\frac{kt}{m}}-\frac{mg}{k}$$
    <br /><br /><br /><br />
    <h2>Parametric Representation of Curves</h2>
    i.e. Projectile Motion.  These are the parametric representations of the trajectory of a projectile: $$x(t)=(v_0\cos\theta)t\quad y(t)=(v_0\sin\theta)t-\frac{1}{2}gt^2$$<br />
    <h3>Calculus with Parametric Curves</h3>
    <h4>Tangents</h4>
    Given $x=f(t)$ and $y=g(t)$,
    $$\frac{dy}{dt}=\frac{dy}{dx}\cdot \frac{dx}{dt}$$
    So, $$\frac{dy}{dx}=\frac{\frac{dy}{dt}}{\frac{dx}{dt}}\quad\frac{dx}{dt}\neq 0$$
    <h4>Areas</h4>
    Given a curve defined by $x=f(t)$ and $y=g(t)$, the area under the curve as $x$ goes from $a$ to $b$ or as $t$ goes from $\alpha$ to $\beta$ can be found by:
    $$A=\int_a^b ydx=\int_\alpha^\beta g(t)f'(t)dt$$<br />
    <h3>Arclength Using Parametric Representation</h3>
    Given a curve $C$ described by $x=f(t)$ and $y=g(t)$ and $f',\ g'$ are continuous over $[a,b]$, and $C$ is traversed exactly once as $t$ goes from $a$ to $b$, find the arclength of the curve in the interval $[a,b]$.
    <ol>
      <li>
        Partition $[a,b]$ into $n$ sub-intervals of width $\Delta t=\frac{b-a}{n}$
      </li>
      <li>
        $$\begin{align*}
        L_k=||\overrightarrow{Q_kQ_{k+1}}||&\approx\sqrt{[f(t_{k+1}-f{t_k})]^2+[g(t_{k+1}-g{t_k})]^2}\\
        &=\Delta t\sqrt{\bigg[\frac{f(t_{k+1}-f{t_k})}{\Delta t}\bigg]^2+\bigg[\frac{g(t_{k+1}-g{t_k})}{\Delta t}\bigg]^2}\\
        &\approx\sqrt{f'(t_k^*)^2+g'(t_k^*)^2}\Delta t
        \end{align*}$$
      </li>
      <li>
        Take the Riemann Sum.
        $$L=\lim_{n\to\infty}\sum_{k=1}^nL_k=\int_a^b\sqrt{f'(t)^2+g'(t)^2}dt$$
      </li>
    </ol>
    Alternatively, we can derive this formula from the formula for arclength of a function $y=f(x)$.
    $$L=\int_a^b\sqrt{1+\big(\frac{dy}{dx}\big)^2}dx=\int_a^b\sqrt{1+\bigg(\frac{\frac{dy}{dt}}{\frac{dx}{dt}}\bigg)^2}dx=\int_a^b\sqrt{\bigg(\frac{dx}{dt}\bigg)^2+\bigg(\frac{dy}{dt}\bigg)^2}dx\cdot\frac{dt}{dx}=\int_a^b\sqrt{\bigg(\frac{dx}{dt}\bigg)^2+\bigg(\frac{dy}{dt}\bigg)^2}dt$$
    <br /><br /><br /><br />
    <h2>Sequences</h2>
    <u>Definition</u>: An infinite set of real numbers ordered $a_1, a_2,\ldots\  $ Denoted as $\{a_n\}$ or $\{a_n\}_{n=1}^\infty$<br />
    <u>Definition</u>: A sequence has the <b>limit</b>, <i>L</i>, which we write as $$\lim_{n=\infty}a_n=L\quad\text{or}\quad a_n\to L\text{ as } n\to\infty$$
    if $\ \forall\epsilon > 0,\ \exists N > 0$ such that $|a_n-L|<\epsilon\quad\forall n>N$<br />
    If the limit exists, then $\{a_n\}$ <b>converges</b>. Otherwise, it <b>diverges</b>.<br />
    If $\{a_n\}$ and $\{b_n\}$ are convergent sequences and $c\in\mathbb{R}$, then
    <ol>
      <li>
        $\lim_{n\to\infty}(a_n+b_n)=\lim_{n\to\infty}a_b+\lim_{n\to\infty}b_n$
      </li>
      <li>
        $\lim_{n\to\infty}ca_n=c\lim_{n\to\infty}a_n$
      </li>
      <li>
        $\lim_{n\to\infty}(a_nb_n)=\lim_{n\to\infty}a_n\cdot\lim_{n\to\infty}b_n$
      </li>
      <li>
        $\lim_{n\to\infty}a_n^p=[\lim_{n\to\infty}a_n]^p\quad$if $p>0$ and $a_n>0$
      </li>
    </ol>
    <h3>Increasing/Decreasing Sequences</h3>
    Given $\{a_n\}$,
    <ol type="a">
      <li>
        <b>Increasing</b>: $a_n < a_{n+1}$ for all $n\geq 1$
      </li>
      <li>
        <b>Decreasing</b>: $a_n > a_{n+1}$ for all $n\geq 1$
      </li>
      <li>
        <b>Monotone</b>: if either increasing or decreasing
      </li>
    </ol>
    <u>Definition</u>: $\{a_n\}$ is <b>bounded above</b> if $\ \exists M$ such that $a_n\leq M\ \ \forall n\geq 1$<br />
    <u>Definition</u>: $\{a_n\}$ is <b>bounded below</b> if $\ \exists m$ such that $a_n\geq m\ \ \forall n\geq 1$<br />
    <u>Definition</u>: $\{a_n\}$ is <b>bounded</b> if $\ \exists m,\ M$ such that $m\leq a_n\leq M\ \ \forall n\geq 1$<br /><br />
    <b><i>Completeness Axiom</i></b>: Let $S\subset\mathbb{R}$ be bounded above such that there exists an $M\in\mathbb{R}$, $x\leq M$ for all $x\in S$.  Then, $S$ has a <b>least upper bound</b> $b$ such that if $M$ is any other upper bound, then $b\leq M$.  **<i>This axiom is used to express that there is no hole or gap in the real number line.</i><br /><br />
    <b><i>Bounded Monotone Sequence Theorem</i></b>: A bounded monotone sequence is convergent (i.e. has a limit)<br />
    <br /><br /><br /><br />
    <h2>Infinite Series</h2>
    Given a sequence $\{a_n\}_{n=1}^\infty$, we consider the series $\sum_{n=1}^\infty a_n$<br />
    <b>Partial Sum</b>: $S_n=a_1+a_2+\cdots+a_n=\sum_{k=1}^n a_k$<br /><br />
    These partial sums for a sequence $\{S_n\}$.<br />
    If $\{S_n\}$ converges and $\lim_{n\to\infty}S_n=S$ exists and is finite, then the series $\sum a_n$ is <b>convergent</b> such that $\sum_{n=1}^\infty a_n=S$, where $S$ is the <b>sum</b> of the series.  If $\{S_n\}$ is divergent, then the series is <b>divergent</b>.<br /><br />
    e.g. Geometric Series<br />
    Consider the geometric series $a+ar+ar^2+\cdots$ where $a_n=ar^{n-1}$, $n\geq 1$.<br />
    Its partial sum is
    $$\begin{align*}
      S_n&=a+ar+\cdots+ar^{n-1}\\
      rS_n&=ar+ar^2+\cdots+ar^n\\
      S_n(1-r)=a-ar^n=a(1-r^n)\\
      S_n=\frac{a(1-r^n)}{1-r}\quad r\neq 1
    \end{align*}$$
    <ol>
      <li>
        If $|r|< 1$, then $r^n\to 0$ as $n\to\infty\ \rightarrow\ \lim_{n\to\infty}S_n=\frac{a}{1-r}\quad$(sum of a geometric series)
      </li>
      <li>
        If $|r|> 1$, then $|S_n|\to\infty$ so the series diverges.
      </li>
      <li>$r=1$, $a+a+a+\cdots$ is divergent.</li>
      <li>$r=-1$, $a-a+a-a+\cdots$ oscillates and is divergent</li>
    </ol>
    Thus, geometric series converge to $\frac{a}{1-r}$ for $|r|< 1$ and diverge for $|r|\geq 1$.<br /><br />
    <h3>Convergence and Divergence of Series</h3>
    <b>Theorem</b>: If $\sum a_n$ is convergent, then $\lim_{n\to\infty}a_n=0$<br />
    <b>Corollary</b>: If $\lim_{n\to\infty}a_n\neq 0$, then $\sum a_n$ is divergent.<br />
    <i>Note: $\lim_{n\to\infty}a_n=0$ does not imply that $\sum a_n$ is convergent. (i.e. Harmonic Series)</i><br /><br />
    <b>Theorem</b>: If $\sum a_n$ and $\sum b_n$ are convergent, then $\sum (a_n+b_n)$ is convergent.
    <h3>Convergence Tests</h3>
    <h4>1. Integral Test</h4>
    If $\sum a_n=f(n)$ where $f(x)$ is continuous, positive and decreasing on $[b,\infty)$, then $$\sum_{n=b}^\infty a_n\text{ is convergent }\Longleftrightarrow\ \int_a^\infty f(x)dx\ \text{ is convergent }$$
    <b><u>Estimating Sums</u></b><br />
    Given $\sum a_n$ converges and its sum is $S$,  its partial sums $S_n$ are approximations to $S$.  For $n\geq 1$, $S=S_n+R_n$ where $R_n$ is the remainder (or the error in approximation).  We can view $R_n$ as the "tail" of the series, $R_n=a_{n+1}+a_{n+2}+\cdots$
    $$R_n\leq \int_n^\infty f(x)dx$$
    <h4>2. Comparison Test</h4>
    Given $\sum a_n$ and $\sum b_n$ where $a_n,b_n>0$ then
    <ol type="i">
      <li>
        If $\sum b_n$ is convergent and $a_n\leq b_n$ for all $n\geq 1$, then $\sum a_n$ is convergent.
      </li>
      <li>
        If $\sum b_n$ is divergent and $a_n\geq b_n$ for all $n\geq 1$, then $\sum a_n$ is divergent.
      </li>
    </ol>
    <i>Tip: Determine what $a_n$ converges to as $n\to\infty$.  If $a_n\to 0$ then find $\sum b_n$ such that $b_n\geq a_n$ for all $n\geq 1$.</i><br /><br />
    e.g. Determine whether $\sum_{n=1}^\infty \frac{5}{2n^2+4n+3}$ converges or diverges.<br />
    We note that as $n\to\infty$, $a_n\to\frac{5}{2n^2}=0$.  Thus, we know it will converge, so we choose $b_n=\frac{5}{2n^2}$.  Since $\frac{5}{2n^2+4n+3}<\frac{5}{2n^2}$ and $b_n$ converges (p-series where $p>1$), thus $\sum_{n=1}^\infty \frac{5}{2n^2+4n+3}$ converges.<br /><br />
    <b><u>Estimating Sums</u></b><br />
    If we have used the Comparison Test to show that a series $\sum a_n$ converges by comparison with $\sum b_n$, then we can compare the remainders.<br />
    Let $R_n$ be the remainder for $\sum a_n$ such that $R_n=s-s_n=a_{n+1}+a_{n+2}+cdots$<br />
    Let $T_n$ be the remainder for $\sum b_n$ such that $T_n=t-t_n=b_{n+1}+b_{n+2}+cdots$<br />
    Since $a_b\leq b_n$ for all $n\geq 1$, then  $R_n\leq T_n$.
    <ul>
      <li>
        If $\sum b_n$ is a geometric series, $T_n=\frac{a}{1-r}$
      </li>
      <li>
        If $\sum b_n$ is a p-series, we use the Remainder Estimate for the Integral Test shown above.
      </li>
    </ul>
    <h4>3. Limit Comparison Test</h4>
    Given $\sum a_n$ and $\sum b_n$ where $a_n,b_n>0$, if $\lim_{n\to\infty}\frac{a_n}{b_n}=c$, where $c$ is finite and $c>0$, then either both converge or both diverge.
    <i>Tip: Determine the dominant term in both the numerator and denominator and use that as $b_n$.</i><br /><br />
    e.g. Determine whether the series $\sum_{n=1}^\infty\frac{2n^3+3n}{\sqrt{5+n^5}}$ converges or diverges.<br />
    Note that the dominant term in the numerator is $2n^2$ and the dominant term in the denominator is $\sqrt{n^5}$.  Thus, we take $b_n=\frac{2n^2}{n^{\frac{5}{2}}}=\frac{2}{n^{\frac{1}{2}}}$.
    $$\begin{align*}
      \lim_{n\to\infty}\frac{a_n}{b_n}=\lim_{n\to\infty}\frac{2n^3+3n}{\sqrt{5+n^5}}\cdot\frac{n^{\frac{1}{2}}}{2}=\lim_{n\to\infty}\frac{2n^{\frac{5}{2}}+3n^{\frac{3}{2}}}{2\sqrt{5+n^5}}=\lim_{n\to\infty}\frac{2+\frac{3}{n}}{2\sqrt{\frac{5}{n^5}+1}}=\frac{2}{2}=1
    \end{align*}$$
    Since $c$ is a positive, finite number, $b_n$ is divergent (p-series with $p< 1$), the given series is divergent by the Limit Comparison Test.<br /><br />
    <h3>Alternating Series</h3>
    If an alternating series $\sum_{n=1}^\infty (-1)^{n-1}b_n$ satisfies
    <ol type="i">
      <li>
        $b_{n+1}\leq b_n$ for all $n$
      </li>
      <li>
        $\lim_{n\to\infty}b_n=0$
      </li>
    </ol>
    then the series is convergent.<br /><br />
    <b><u>Alternating Series Estimation Theorem</u></b><br />
    If $\sum (-1)^{n-1}b_n$, $b_n>0$, satisfies the conditions for an alternating series, then $|R_n|=|s-s_n|\leq b_{n+1}$.<br /><br />
    <h3>Absolute Convergence</h3>
    <u>Definition</u>: A series $\sum a_n$ is called <b>absolutely convergent</b> if the series $\sum|a_n|$ is convergent.<br />
    <u>Definition</u>: A series $\sum a_n$ is called <b>conditionally convergent</b> if it is convergent but not absolutely convergent. <br /><br />
    <u>Theorem</u>: If a series $\sum a_n$ is absolutely convergent, then it is convergent.
    <h4>4. Ratio Test</h4>
    Given a series $\sum a_n$, let $\lim_{n\to\infty}\bigg|\frac{a_{n+1}}{a_n}\bigg| = L$
    <ol type="i">
      <li>
        If $L< 1$, then $\sum a_n$ is absolutely convergent (and therefore convergent).
      </li>
      <li>
        If $L>1$ or $L=\infty$, then $\sum a_n$ is divergent.
      </li>
      <li>
        If $L=1$, test is inconclusive.
      </li>
    </ol>
    <h4>5. Root Test</h4>
    This is used when $n$th power occurs.<br />
    Given a series $\sum a_n$, let $\lim_{n\to\infty}\sqrt{|a_n|} = L$
    <ol type="i">
      <li>
        If $L< 1$, then $\sum a_n$ is absolutely convergent (and therefore convergent).
      </li>
      <li>
        If $L>1$ or $L=\infty$, then $\sum a_n$ is divergent.
      </li>
      <li>
        If $L=1$, test is inconclusive.
      </li>
    </ol>
    <br /><br /><br /><br />
    <h2>Power Series</h2>
	  A <em>power series about a</em> is a series that can be written in the form of $$\sum_{n=0}^{\infty} c_{n}(x-a)^{n}$$
	  Where $a, c_{n} \in \mathbb{R}$. Some things to note are the $c_{n}$'s are often called the <strong>coefficients</strong> of the series, and that the series is a function of $x$.<br />
    <u>Theorem</u>: For a given power series $\sum_{n=0}^\infty c_n(x-a)^n$, there are only three possibilities for convergence:
    <ol type="i">
      <li>
        Converges only at $x=a$.
      </li>
      <li>
        Converges for all $x$.
      </li>
      <li>
        Converges if $|x-a|< R$ and diverges if $|x-a| > R$ for $R>0$.  There are four possibilities:
        $$(a-R, a+R)\quad\quad[a-R, a+R]\quad\quad(a-R, a+R]\quad\quad[a-R, a+R)$$
      </li>
    </ol>
    To find the radius of convergence, apply the ratio test and test at endpoints.<br /><br />
    e.g. Find the radius of convergence and interval of convergence of $\sum_{n=0}^\infty \frac{(-3)^nx^n}{\sqrt{n+1}}$.<br /><br />
    Let $a_n=\frac{(-3)^nx^n}{\sqrt{n+1}}$.  Applying the ratio test, we get
    $$\lim_{n\to\infty}\bigg|\frac{a_{n+1}}{a_n}\bigg|=\bigg|\frac{(-3)^{n+1}x^{n+1}}{\sqrt{n+2}}\cdot\frac{\sqrt{n+1}}{(-3)^nx^n}\bigg|=\bigg|-3x\sqrt{\frac{n+1}{n+2}}\bigg|=3|x|\sqrt{\frac{1+\frac{1}{n}}{1+\frac{2}{n}}}\rightarrow 3|x|\quad\text{as }n\to\infty$$
    By the ratio test, the series converges if $3|x|< 1$ and diverges if $3|x| > 1$.  Thus, it converges if $x<|\frac{1}{3}|$ and diverges if $x>|\frac{1}{3}|$.  So, the <b>radius of convergence</b> is $R=\frac{1}{3}$.<br />
    We now test for the endpoints.  When $x=-\frac{1}{3}$, the series becomes $\sum_{n=0}^\infty \frac{(-3)^n(-\frac{1}{3})^n}{\sqrt{n+1}}=\sum_{n=0}^\infty \frac{1}{\sqrt{n+1}}$, which diverges (p-series with $p = \frac{1}{2} < 1$).  When $x=\frac{1}{3}$, the series becomes \sum_{n=0}^\infty \frac{(-1)^n}{\sqrt{n+1}}$ which converges by the Alternating Series Test. Thus, the <b>interval of convergence</b> is $\big(-\frac{1}{3}, \frac{1}{3}\big]$.
    <h3>Representations of Functions as Power Series</h3>
    Functions can be modelled with a power series by manipulating the geometric series or by differentiating or integrating the series.  <br />
    <u>Useful for</u>: Integrating functions without an elementary antiderivative,  solving differential equations, and approximating functions by polynomials.
    <h4>Representation of Functions with the Geometric Series</h4>
    $$\frac{1}{1-x}=1+x+x^2+\cdots=\sum_{n=0}^\infty x^n\quad |x|< 1$$
    <h4>Manipulating Series</h4>
    You can manipulate series by:
    <ol>
      <li>Substituting into $x$</li>
      <li>Multiplying</li>
      <li>Adding</li>
    </ol>
    e.g. Find a power series representation of $\frac{x^3}{x+2}$.<br />
    We note that this is very similar to the function represented by a geometric series as shown above.
    $$\frac{x^3}{x+2}=x^3\cdot\frac{1}{2+x}=\frac{x^3}{2}\cdot\frac{1}{1+\frac{x}{2}}\quad (a = 1,\ r = -\frac{x}{2})$$
    $$\frac{x^3}{x+2}=\frac{x^3}{2}\sum_{n=0}^\infty (-\frac{x}{2})^n=\sum_{n=0}^\infty (-1)^n\frac{x^{n+3}}{2^{n+1}}$$
    Since this is a geometric series, we know that it converges when $|r| < 1$ or $|-\frac{x}{2}|< 1 \rightarrow x < 2$. Thus the radius of convergence is $R=2$ and the interval of convergence is $(-2, 2)$.
    <h4>Differentiation and Integration of Power Series</h4>
    <u>Theorem</u>: If the power series $\sum c_n(x-a)^n$ has radius of convergence $R>0$ then the function defined by:
    $$f(x)=c_0+c_1(x-a)+c_2(x-a)^2+cdots=\sum c_n(x-a)^n$$
    is differentiable and continuous on the interval $(a-R,a+R)$ and
    <ol type="i">
      <li>
        $$f'(x)=c_1+2c_2(x-a)+3c_3(x-a)^2+\cdots=\sum nc_n(x-a)^{n-1}\quad\text{or}$$
        $$\frac{d}{dx}\bigg[\sum c_n(x-a)^n\bigg]=\sum \frac{d}{dx}[c_n(x-a)^n]$$
      </li>
      <li>
        $$\int f(x)dx=C+c_0(x-a)+c_1\frac{(x-a)^2}{2}+c_2\frac{(x-a)^3}{3}+\cdots=C+\sum c_n\frac{(x-a)^{n+1}}{n+1}\quad\text{or}$$
        $$\int\bigg[\sum c_n(x-a)^n\bigg]dx=\sum \int[c_n(x-a)^n]dx$$
      </li>
    </ol>
  </body>
</html>
